{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: model refinement ideas (blog post summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mainly a summary of the following blog post on Kaggle: Titanic - Advanced Feature Engineering Tutorial ([link](https://www.kaggle.com/code/gunesevitan/titanic-advanced-feature-engineering-tutorial)). The summaries after each section in the post are very helpful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Exploratory data analysis\n",
    "\n",
    "1. `Age`, `Cabin` and `Embarked` are commonly missing variables in the training set. Gunes has a function that displays how many missing values there are in each variable.\n",
    "1. `Age` varies a lot by `Sex`, `PClass` etc, so imputation should take that into account.\n",
    "1. `Embarked` and `Fare` (test set) are only missing for a couple of people. Use imputation based on the characteristics of those people.\n",
    "1. `Cabin` is a very interesting feature.\n",
    "    1. The first letter of the cabin tells you what deck the cabin it was on. **A** , **B** and **C** were only for first class, **D** and **E** were for all classes, **F** and **G** were for both 2nd and 3rd class passengers. You can plot these distributions if you would like. Going from **A** to **G**, distance to the staircase increases which might be a factor of survival.\n",
    "    1. You can plot survival probabilty by deck\n",
    "    1. You can group decks together to reduce dimensionality\n",
    "1. Gunes created a new feature `Deck` and dropped the `Cabin` feature.\n",
    "1. You can plot correlations between variables. There are a lot of correlated variables.\n",
    "1. You can plot distributions of numeric and categorical variables by survival. Gunes' plots are counts, my plots are \"prob survival\". I like my version more. \n",
    "1. Split points / spikes are visible in continuous features. They can be captured easily with a decision tree model, but linear models may not be able to spot them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Section 2: Feature Engineering\n",
    "\n",
    "1. Bin `Fare` using `pd.qcut(df['Fare'], 13)`, plot survival counts with new fare variable.\n",
    "1. Bin `Age` the same way, use 10 quantile based bins, plot survival counts with this.\n",
    "1. Encode `Family_Size` by combining `SibSp` and `Parch`. Values are **Alone**, **Small**, **Medium** and **Large**. Plot survival by this variable. \n",
    "1. See how many people are on each `Ticket`, create a `Ticket_Frequency` feature based on this, `df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')`. This is similar to `Family Size`\n",
    "1. Create a `Title` feature for the first word in someone's Name. Create a `Is_Married` feature based on the title `Mrs`.\n",
    "    1. Nice way to do ifelses: `df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')`\n",
    "1. Extract surnames and create a `Family` feature based on it. Create a family survival rate feature. \n",
    "1. Add ticket and family survival rates in both the train and test data based on average survival rate in the ticket or family in the training data. This seems like a pretty sketchy method since it seems like we are leaking data, so I don't think that I will do it.\n",
    "1. Label encode non-numerical features:\n",
    "    1. Non numeric features are converted to numerical type with `LabelEncoder`. `LabelEncoder` basically labels the classes from 0 to n. Variables will look like `Embarked_0`, `Embarked_1` etc.\n",
    "    1. `non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']`\n",
    "    1. `LabelEncoder().fit_transform(df[feature])`\n",
    "1. One-Hot encode categorical features:\n",
    "    1. `cat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped']`\n",
    "    1. `OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()`\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final features for classifier in blog post:\n",
    "1. `Age`: Binned into 10 quantile based bins\n",
    "1. `Fare`: Binned into 13 quantile based bins\n",
    "1. `Deck`: One hot encoded into four decks\n",
    "1. `Title`: One hot encoded into categories (*Miss/Mrs/Ms*, *Dr/Military/Noble/Clergy*, *Master* (a male under age of 26), *Mr*)\n",
    "1. `Family_Size_Grouped`: One hot encoded into four \"family sizes\"\n",
    "1. `Embarked`: One hot encoded into the three cities\n",
    "1. `Is_Married`: One hot encoded \n",
    "1. `Pclass`: One hot encoded into three classes\n",
    "1. `Sex`: One hot encoded\n",
    "1. `Survival_Rate`: Average of family and ticket survival rates (don't do this...seems like data leakage).\n",
    "1. `Survival_Rate_NA`: Whether the survival rate is NA or not.\n",
    "1. `Ticket_Frequency`: How many people are on the person's ticket (this clearly seems like train/test leakage, since it is computed on both variables)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding** vs **One-Hot Encoding**: Label encoding gives you an ordinal value (1 is bigger than 0, 2 is bigger than 1), while One-Hot encoding just gives you 0's and 1's"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My roadmap for improving my classifier:\n",
    "1. *[done]* Bin training set `Age` and `Fare`, and make survival plots based on the quantiles. \n",
    "1. *[done]* Figure out how to impute `NaN`s taking feature correlations into account.\n",
    "1. *[done]* Get a full pipeline to work with an advanced imputation methodology\n",
    "1. *[done]* Modify code to do cross validator for AUC metrics (not just one train test split). \n",
    "    1. Figure out how to summarize AUC and PR metrics across folds (use `np.interp`?)\n",
    "\n",
    "1. *[done]* NLP `Cabin` and `Name` features to extract `Deck` and `Title`. Plot survival vs these new features.\n",
    "    1. Make an `Is_Married` feature.\n",
    "1. *[done]* Create a `Family_Size_Grouped` feature by exploring and analyzing training set family size (`Parch` and `SibSp`). Plot survival rates by these features.\n",
    "1. Feature importance plot for model evaluation\n",
    "1. Hyperparameter optimization\n",
    "1. Combine notebooks to be one clearly defined narrative. Have one top cell that does most of the feature engineering.\n",
    "\n",
    "Ideas I've already done\n",
    "1. One hot encode `Embarked`, `Pclass`, `Sex`.\n",
    "1. Train models with continuous and binned `Age` / `Fare` variables to see which is better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My history of improvements to the model\n",
    "1. Baseline AUC ~0.84\n",
    "1. Using better imputing (eg IterativeImputer) improves AUC to ~0.85 (~13 columns)\n",
    "1. Discretizing Age and Fare improves AUC to ~0.87. The age/fare buckets are one-hot encoded (~41 columns)\n",
    "\n",
    "**Jan 21 2023** -- actually the AUC for discretizing vs standardizing age and fare is about the same when you do 10-fold cross validation -- it's between 0.850 and 0.853"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 22 2023** Let's see whether sklearn pipelines are the right thing to do, or whether we should just do the pre-processing in a function. Pre-processing steps:\n",
    "1. `Age` and `Fare` should be binned or standardized\n",
    "1. Make a family size column based on `SibSp` and `Parch`. \n",
    "1. [done]One hot encode `Pclass`, `Sex`, `Embarked`\n",
    "1. [done]Create a `Deck` feature, one hot encode it, potentially use a `CabinNo` feature\n",
    "1. [done]Create a `Married` feature, extract `Title` feature from names\n",
    "\n",
    "`numeric_cols = ['SibSp', 'Parch', 'CabinNo', 'Fare', 'Age']`\n",
    "\n",
    "`categorical_cols = ['Pclass', 'Sex', 'Embarked', 'Deck', 'Title']`\n",
    "\n",
    "General notebook structure\n",
    "1. Start with data exploration and feature engineering\n",
    "1. Then go into model training?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**April 3 2023** Prep for meeting Maggie\n",
    "\n",
    "1. Check if updating sklearn leads to you being able to get feature names out\n",
    "1. Use full data (not just Kaggle training set)\n",
    "1. Put together a pipeline implementation, maybe try rotating imputers / disc vs scale for hyperparameter optimization\n",
    "1. Do hyperparameter optimization\n",
    "1. Make a feature importances plot\n",
    "1. Plot learning curve / check for overfitting?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open questions / observations about the process:\n",
    "1. Imputation / preprocessing is really important. \n",
    "1. How important is being fastidious about train test leakage (eg. should we make dummy variables, do mean scaling only using training set?)\n",
    "1. How should we plot PR curves / ROC curves after k-fold cross validation?\n",
    "1. How do we mix hyperparameter optimization / gridsearch with model structure selection? Maybe we can add scale vs discretize to the hyperparameter grid? [Example](https://towardsdatascience.com/getting-the-most-out-of-scikit-learn-pipelines-c2afc4410f1a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful blogposts:\n",
    "\n",
    "[Hyperparameter optimization with pipelines](https://towardsdatascience.com/getting-the-most-out-of-scikit-learn-pipelines-c2afc4410f1a)\n",
    "\n",
    "[How to keep feature names with pipelines](https://medium.com/@anderson.riciamorim/how-to-keep-feature-names-in-sklearn-pipeline-e00295359e31)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Model\n",
    "\n",
    "1. Standard scale all columns\n",
    "1. Random forest models (leaderboard model overfits to the test data, single best model is more resilient):\n",
    "\n",
    "    ```\n",
    "    single_best_model = RandomForestClassifier(criterion='gini', \n",
    "                                            n_estimators=1100,\n",
    "                                            max_depth=5,\n",
    "                                            min_samples_split=4,\n",
    "                                            min_samples_leaf=5,\n",
    "                                            max_features='auto',\n",
    "                                            oob_score=True,\n",
    "                                            random_state=SEED,\n",
    "                                            n_jobs=-1,\n",
    "                                            verbose=1)\n",
    "\n",
    "    leaderboard_model = RandomForestClassifier(criterion='gini',\n",
    "                                            n_estimators=1750,\n",
    "                                            max_depth=7,\n",
    "                                            min_samples_split=6,\n",
    "                                            min_samples_leaf=6,\n",
    "                                            max_features='auto',\n",
    "                                            oob_score=True,\n",
    "                                            random_state=SEED,\n",
    "                                            n_jobs=-1,\n",
    "                                            verbose=1) \n",
    "    ```\n",
    "\n",
    "1. Use a `StratifiedKFold` with 5 splits to train the models, and get AUC scores.\n",
    "1. Get predictions and feature importances:\n",
    "    1. `leaderboard_model.predict_proba(X_test)[:, 1]`\n",
    "    1. `leaderboard_model.feature_importances_`\n",
    "1. Plot feature importances, ROC curves (averaging over the 5 folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
